{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 每個檔案(每日檔案數量, 每日顧客唯一數量, 每日商品唯一數量, 每日顧客X商品唯一數量)\n",
    "2. Information of  file, cust, prod and custXprod each day, such as (max - min).\n",
    "3. list 每個檔案(每日檔案數量, 每日顧客唯一數量, 每日商品唯一數量, 每日顧客X商品唯一數量) each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_ct_uct(df_val):\n",
    "    f = {'customer_id': ['count', lambda x: len(set(x))],\n",
    "         'product_id': lambda x: len(set(x)),\n",
    "         'custXprod_id': lambda x: len(set(x)),\n",
    "         'date_new': [\"max\", \"min\", lambda x: len(set(x))]\n",
    "    }\n",
    "    g = df_val.groupby([\"file_id\"]).aggregate(f).reset_index()\n",
    "    g.columns = [\"file_id\", \"file_ct\", \"cust_uct\", \"prod_uct\", \"custXprod_uct\",\n",
    "                 \"date_max\", \"date_min\", \"date_count\"]\n",
    "\n",
    "    g[\"date_during\"] = g.date_max - g.date_min + 1\n",
    "    g[\"file_freq\"] = g.file_ct / g.date_count\n",
    "    g[\"custXprod_freq\"] = g.custXprod_uct / g.date_count\n",
    "\n",
    "    print (\"feature of cust, prod and date :\", g.shape)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_minus_one(x):\n",
    "    x = list(x)\n",
    "    if len(x) > 1:\n",
    "        m_ = x[1] - x[0]\n",
    "    else:\n",
    "        m_ = x[0] - x[0]\n",
    "    return m_\n",
    "\n",
    "\n",
    "def groupby_ct_uct_ed(df_val):\n",
    "    # step 1: 算出每天的資訊\n",
    "    f1 = {'customer_id': ['count', lambda x: len(set(x))],\n",
    "          'product_id': lambda x: len(set(x)),\n",
    "          'custXprod_id': lambda x: len(set(x))\n",
    "    }\n",
    "    g1 = df_val.groupby([\"file_id\", \"date_new\"]).aggregate(f1).reset_index()\n",
    "    g1.columns = [\"file_id\", \"date_new\",\n",
    "                  \"file_ct_ed\", \"cust_uct_ed\", \"prod_uct_ed\", \"custXprod_uct_ed\"]\n",
    "\n",
    "    # step 2: max_minus_min, two_minus_one\n",
    "    f3 = {'file_ct_ed': [lambda x: max(x) - min(x)],\n",
    "          'custXprod_uct_ed': [lambda x: max(x) - min(x)]\n",
    "    }\n",
    "    g4_1 = g1.groupby(['file_id']).agg(f3).reset_index()\n",
    "    g4_1.columns = [\"file_id\",\"file_ct_ed_mmm\", \"custXprod_uct_ed_mmm\"]\n",
    "\n",
    "    f4 = {\"file_ct_ed\": lambda x: two_minus_one(x),\n",
    "          \"custXprod_uct_ed\": lambda x: two_minus_one(x)}\n",
    "    g4_2 = g1.groupby(['file_id']).agg(f4).reset_index()\n",
    "    g4_2.columns = ['file_id','file_ct_ed','custXprod_uct_ed']\n",
    "\n",
    "    g4 = pd.merge(g4_1, g4_2, how=\"left\", on=\"file_id\")\n",
    "    print (\"feature about each day :\",g4.shape)\n",
    "\n",
    "    # step 3: list number each day\n",
    "    f2 = lambda x: x - min(x)\n",
    "\n",
    "    g1_1 = g1.groupby('file_id')[\"date_new\"].apply(f2).reset_index(drop = True)\n",
    "    g1[\"date_perfile\"] = g1_1\n",
    "\n",
    "    g2_col = ['file_id']\n",
    "    for d in range(6):\n",
    "        for varible_ in g1.columns[2:6]:\n",
    "            g2_col.append(varible_ + \"_d\" + str(d))\n",
    "\n",
    "    g2 = g1[(g1.date_perfile == 0)]\n",
    "    g2 = g2.drop(['date_new', 'date_perfile'], axis=1)\n",
    "    for i in range(1, 6):\n",
    "        g1_ = g1[(g1.date_perfile == i)]\n",
    "        g1_ = g1_.drop(['date_new', 'date_perfile'], axis=1)\n",
    "        g2 = pd.merge(g2, g1_, how=\"left\", on=\"file_id\")\n",
    "\n",
    "    g2 = g2.fillna(0)\n",
    "    g2.columns = g2_col\n",
    "    print (\"feature about each day :\", g2.shape)\n",
    "    \n",
    "    return g2, g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature of cust, prod and date : (52518, 11)\n",
      "feature about each day : (52518, 5)\n",
      "feature about each day : (52518, 25)\n",
      "(52518, 39)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file_ in [\"train1\",\"train2\",\"train3\",\"valid\"]:\n",
    "    df_ = pd.read_pickle(\"dataset/\" + str(file_) + \".pkl\")\n",
    "    df = pd.concat([df, df_], axis=0)\n",
    "\n",
    "df['custXprod_id'] = df.customer_id + df.product_id\n",
    "\n",
    "g_train = groupby_ct_uct(df)\n",
    "g2, g4 = groupby_ct_uct_ed(df)\n",
    "\n",
    "g_train = pd.merge(g_train, g2, how = \"left\", on = \"file_id\")\n",
    "g_train = pd.merge(g_train, g4, how = \"left\", on = \"file_id\")\n",
    "print (g_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature of cust, prod and date : (29376, 11)\n",
      "feature about each day : (29376, 5)\n",
      "feature about each day : (29376, 25)\n",
      "(29376, 39)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file_ in [\"test_1\",\"test_2\",\"test_3\"]:\n",
    "    df_ = pd.read_pickle(\"dataset/\" + str(file_) + \".pkl\")\n",
    "    df = pd.concat([df, df_], axis=0)\n",
    "\n",
    "df['custXprod_id'] = df.customer_id + df.product_id\n",
    "\n",
    "g_test = groupby_ct_uct(df)\n",
    "g2, g4 = groupby_ct_uct_ed(df)\n",
    "\n",
    "g_test = pd.merge(g_test, g2, how = \"left\", on = \"file_id\")\n",
    "g_test = pd.merge(g_test, g4, how = \"left\", on = \"file_id\")\n",
    "print (g_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.concat([g_train, g_test], axis=0)\n",
    "g.to_csv(\"dataset/file_cust_prod_ct_uct.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81894, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "file_id                 04f6e4a3745d8016a3e61e097b8b573f\n",
       "file_ct                                             4679\n",
       "cust_uct                                            3796\n",
       "prod_uct                                               7\n",
       "custXprod_uct                                       3798\n",
       "date_max                                               8\n",
       "date_min                                               3\n",
       "date_count                                             6\n",
       "date_during                                            6\n",
       "file_freq                                        779.833\n",
       "custXprod_freq                                       633\n",
       "file_ct_ed_d0                                        232\n",
       "cust_uct_ed_d0                                       162\n",
       "prod_uct_ed_d0                                         3\n",
       "custXprod_uct_ed_d0                                  162\n",
       "file_ct_ed_d1                                        481\n",
       "cust_uct_ed_d1                                       380\n",
       "prod_uct_ed_d1                                         3\n",
       "custXprod_uct_ed_d1                                  380\n",
       "file_ct_ed_d2                                        276\n",
       "cust_uct_ed_d2                                       243\n",
       "prod_uct_ed_d2                                         3\n",
       "custXprod_uct_ed_d2                                  243\n",
       "file_ct_ed_d3                                        366\n",
       "cust_uct_ed_d3                                       306\n",
       "prod_uct_ed_d3                                         3\n",
       "custXprod_uct_ed_d3                                  307\n",
       "file_ct_ed_d4                                       1275\n",
       "cust_uct_ed_d4                                      1096\n",
       "prod_uct_ed_d4                                         6\n",
       "custXprod_uct_ed_d4                                 1097\n",
       "file_ct_ed_d5                                       2049\n",
       "cust_uct_ed_d5                                      1797\n",
       "prod_uct_ed_d5                                         6\n",
       "custXprod_uct_ed_d5                                 1797\n",
       "file_ct_ed_mmm                                      1817\n",
       "custXprod_uct_ed_mmm                                1635\n",
       "file_ct_ed                                           249\n",
       "custXprod_uct_ed                                     218\n",
       "Name: 1000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (g.shape)\n",
    "g.iloc[1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
