{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to hour, minute, second\n",
    "\n",
    "def add_time_string(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"queryts_new\"] = pd.DataFrame(pd.to_datetime(df.queryts, unit='s'))\n",
    "    df.queryts_new = df.queryts_new.astype(str)\n",
    "\n",
    "    con = pd.DataFrame(df.queryts_new.str.split(\" \",2).tolist(), columns = ['a','b'])\n",
    "    con1 = pd.DataFrame(con.b.str.split(\":\",3).tolist(), columns = ['hr','mins','sec'])\n",
    "    df[\"mins\"] = con1.mins\n",
    "    df.mins = pd.to_numeric(df.mins, errors = 'coerce')\n",
    "    \n",
    "    df = df.drop(\n",
    "        [\"customer_id\",\"queryts\",\"product_id\",\"month\",\"date\",\"date_new\",\"queryts_new\"], axis=1)\n",
    "\n",
    "    print (df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_interval_six(x):\n",
    "    x = pd.Series(x)\n",
    "    hr5 = sum(x < 15)\n",
    "    hr11 = sum(x < 30)\n",
    "    hr17 = sum(x < 45)\n",
    "    hr23 = sum(x < 60)\n",
    "    hr_0_5 = hr5\n",
    "    hr_6_11 = hr11 - hr5\n",
    "    hr_12_17 = hr17 - hr11\n",
    "    hr_18_23 = hr23 - hr17\n",
    "    return hr_0_5, hr_6_11, hr_12_17, hr_18_23\n",
    "\n",
    "def groupby_count_interval_six(df):\n",
    "    f = {'mins': lambda x: count_interval_six(x)}\n",
    "\n",
    "    g = df.groupby([\"file_id\"]).aggregate(f).reset_index()\n",
    "    g.columns = [\"file_id\", \"count_interval_six_list\"]\n",
    "\n",
    "    g_ = g['count_interval_six_list'].apply(pd.Series)\n",
    "    g_.columns = [\"mins_0_14\", \"mins_15_29\", \"mins_30_44\", \"mins_45_59\"]\n",
    "    g = pd.concat([g[[\"file_id\"]], g_], axis=1)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54250245, 2)\n",
      "(52518, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file_ in [\"train1\",\"train2\",\"train3\",\"valid\"]:\n",
    "    df_ = pd.read_pickle(\"dataset/\" + str(file_) + \".pkl\")\n",
    "    df = pd.concat([df, df_], axis=0)\n",
    "    \n",
    "df = add_time_string(df)\n",
    "g_train = groupby_count_interval_six(df)\n",
    "\n",
    "print (g_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29022865, 2)\n",
      "(29376, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file_ in [\"test_1\",\"test_2\",\"test_3\"]:\n",
    "    df_ = pd.read_pickle(\"dataset/\" + str(file_) + \".pkl\")\n",
    "    df = pd.concat([df, df_], axis=0)\n",
    "\n",
    "df = add_time_string(df)\n",
    "g_test = groupby_count_interval_six(df)\n",
    "\n",
    "print (g_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.concat([g_train, g_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.to_csv(\"dataset/count_min_interval_15.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
