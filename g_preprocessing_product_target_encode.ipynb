{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46639952, 7)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for file_ in [\"train1\",\"train2\",\"train3\"]:\n",
    "    df_ = pd.read_pickle(\"dataset/\" + str(file_) + \".pkl\")\n",
    "    df_train = pd.concat([df_train, df_], axis=0)\n",
    "\n",
    "print (df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36633158, 7)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "for file_ in [\"test_1\",\"test_2\",\"test_3\",\"valid\"]:\n",
    "    df_ = pd.read_pickle(\"dataset/\" + str(file_) + \".pkl\")\n",
    "    df_test = pd.concat([df_test, df_], axis=0)\n",
    "\n",
    "print (df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81977, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train_set = pd.read_csv(\"dataset/training-set.csv\")\n",
    "df_test_set = pd.read_csv(\"dataset/testing-set.csv\")\n",
    "df_set = pd.concat([df_train_set, df_test_set], axis=0)\n",
    "\n",
    "print (df_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_train_set, how=\"left\", on=\"file_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_id        0\n",
       "customer_id    0\n",
       "queryts        0\n",
       "product_id     0\n",
       "month          0\n",
       "date           0\n",
       "date_new       0\n",
       "label          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 商品行為"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "col = []\n",
    "for type_ in [\"_train\", \"_test\"]:\n",
    "    col.append(\"product_id\")\n",
    "    for col_ in [\"count\",\"hr_mean\",\"date_max\",\"date_min\",\"date_count\"]:\n",
    "        col.append(col_ + type_)\n",
    "\n",
    "f = {\n",
    "    'hr': ['count', 'mean'],\n",
    "    'date_new': ['max', 'min', lambda x: len(set(x))],\n",
    "}\n",
    "g_train = df_train.groupby([\"product_id\"]).aggregate(f).reset_index()\n",
    "g_train.columns = col[:6]\n",
    "g_test = df_test.groupby([\"product_id\"]).aggregate(f).reset_index()\n",
    "g_test.columns = col[6:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g = pd.merge(g_train, g_test, how=\"outer\", on=\"product_id\")\n",
    "g = g.fillna(0)\n",
    "\n",
    "g_ = pd.DataFrame(g.product_id, columns=[\"product_id\"])\n",
    "g_[\"prod_count\"] = g.count_train + g.count_test\n",
    "g_[\"prod_hr_mean\"] = (g.count_train*g.hr_mean_train + g.count_test*g.hr_mean_test) / g_.prod_count\n",
    "g_[\"prod_date_count\"] = g.date_count_train + g.date_count_test\n",
    "g_[\"prod_date_max\"] = g[['date_max_train', 'date_max_test']].max(axis=1)\n",
    "g_[\"prod_date_min\"] = g[['date_min_train', 'date_min_test']].min(axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g_.to_csv(\"dataset/product_id.csv\", index = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g = g_[(g_.prod_date_count > 7)&(g_.prod_date_min < 61)&(g_.prod_date_max > 60)]\n",
    "\n",
    "print (g.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train = df_train[df_train['product_id'].isin(g.product_id)].reset_index(drop=True)\n",
    "df_test = df_test[df_test['product_id'].isin(g.product_id)].reset_index(drop=True)\n",
    "\n",
    "print (df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None, \n",
    "                  tst_series=None, \n",
    "                  target=None, \n",
    "                  min_samples_leaf=1, \n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "    \"\"\" \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by = trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, sub = target_encode(df_train[\"product_id\"], \n",
    "                         df_test[\"product_id\"], \n",
    "                         target=df_train.label, \n",
    "                         min_samples_leaf=100,\n",
    "                         smoothing=10,\n",
    "                         noise_level=0.01)\n",
    "df_train[\"prod_enc\"] = trn\n",
    "df_test[\"prod_enc\"] = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81894, 5)\n"
     ]
    }
   ],
   "source": [
    "f = {'prod_enc': ['mean', 'std', 'max', 'min']}\n",
    "g_train = df_train.groupby([\"file_id\"]).aggregate(f).reset_index()\n",
    "g_train.columns = [\"file_id\",\"prod_enc_mean\",\"prod_enc_std\",\"prod_enc_max\",\"prod_enc_min\"]\n",
    "\n",
    "g_test = df_test.groupby([\"file_id\"]).aggregate(f).reset_index()\n",
    "g_test.columns = [\"file_id\",\"prod_enc_mean\",\"prod_enc_std\",\"prod_enc_max\",\"prod_enc_min\"]\n",
    "g = pd.concat([g_train, g_test], axis=0)\n",
    "\n",
    "f = {'prod_enc_mean': 'mean','prod_enc_std': 'mean',\n",
    "     'prod_enc_max': 'max','prod_enc_min': 'min'}\n",
    "g = g.groupby([\"file_id\"]).aggregate(f).reset_index()\n",
    "g.columns = [\"file_id\",\"prod_enc_mean\",\"prod_enc_std\",\"prod_enc_max\",\"prod_enc_min\"]\n",
    "\n",
    "print (g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_id          00008c73ee43c15b16c26b26398c1577\n",
       "prod_enc_mean                            0.125596\n",
       "prod_enc_std                            0.0496438\n",
       "prod_enc_max                             0.240221\n",
       "prod_enc_min                            0.0316121\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.to_csv(\"dataset/prod_enc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
